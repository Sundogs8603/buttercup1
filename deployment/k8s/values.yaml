# Global values available to all charts
global:
  # Set environment: "minikube" or "aks"
  environment: "minikube"
  ossFuzzContainerOrg: "aixcc-afc"
  orchestratorImage:
    repository: ghcr.io/aixcc-finals/afc-crs-trail-of-bits/buttercup-orchestrator
    tag: "main"
    pullPolicy: Always
    pullSecrets: ["ghcr-auth"]
  fuzzerImage:
    repository: ghcr.io/aixcc-finals/afc-crs-trail-of-bits/buttercup-fuzzer
    tag: "main"
    pullPolicy: Always
    pullSecrets: ["ghcr-auth"]
  seedGenImage:
    repository: ghcr.io/aixcc-finals/afc-crs-trail-of-bits/buttercup-seed-gen
    tag: "main"
    pullPolicy: Always
    pullSecrets: ["ghcr-auth"]
  patcherImage:
    repository: ghcr.io/aixcc-finals/afc-crs-trail-of-bits/buttercup-patcher
    tag: "main"
    pullPolicy: Always
    pullSecrets: ["ghcr-auth"]
  programModelImage:
    repository: ghcr.io/aixcc-finals/afc-crs-trail-of-bits/buttercup-program-model
    tag: "main"
    pullPolicy: Always
    pullSecrets: ["ghcr-auth"]
  competitionApiImage:
    repository: ghcr.io/aixcc-finals/example-crs-architecture/competition-test-api
    tag: v1.2-rc1
    pullPolicy: Always
    pullSecrets: ["ghcr-auth"]

  # Default sample size for the coverage bot
  coverageBot:
    sampleSize: 200

  # Langfuse global configuration for all subcharts
  langfuse:
    enabled: false
    host: "https://cloud.langfuse.com"
    publicKey: "pk-lf-..."  # Replace with your actual public key
    secretKey: "sk-lf-..."  # Replace with your actual secret key
  crs:
    api_key_id: 515cc8a0-3019-4c9f-8c1c-72d0b54ae561
    api_key_token: VGuAC8axfOnFXKBB7irpNDOKcDjOlnyB
    api_key_token_hash: "$argon2id$v=19$m=65536,t=3,p=4$Dg1v6NPGTyXPoOPF4ozD5A$wa/85ttk17bBsIASSwdR/uGz5UKN/bZuu4wu+JIy1iA"
    # api_url: "https://api.tail7e9b4c.ts.net"
    hostname: "buttercup-crs"
    competition_api_key_id: 11111111-1111-1111-1111-111111111111
    competition_api_key_token: secret
    # competition_api_url: "https://api.tail7e9b4c.ts.net"
  otel:
    endpoint: "https://127.0.0.1:4318" # TODO: Change to the actual endpoint
    token: "token"
    protocol: "grpc"
  queueTimeouts:
    buildTaskTimeoutMs: 120000
    buildOutputTaskTimeoutMs: 120000
    downloadTaskTimeoutMs: 120000
    readyTaskTimeoutMs: 120000
    deleteTaskTimeoutMs: 120000
    crashTaskTimeoutMs: 120000
    patchTaskTimeoutMs: 120000
    confirmedVulnerabilitiesTaskTimeoutMs: 120000
    indexTaskTimeoutMs: 120000
    indexOutputTaskTimeoutMs: 120000
    tracedVulnerabilitiesTaskTimeoutMs: 120000
  # Node-local storage configuration to be accessible by all subcharts
  volumes:
    nodeLocal:
      enabled: true
      hostPath: /node_data_storage
      type: DirectoryOrCreate
      mountPath: /node_data

# Volume configurations
volumes:
  tasks_storage:
    enabled: true
    # When using AKS, specify the appropriate storage class for ReadWriteMany support
    # For example: "azurefile-csi-nfs-${BUTTERCUP_NAMESPACE}"
    storageClass: ""  # Empty string will use cluster default
    size: "5Gi"
    accessMode: ReadWriteMany
  crs_scratch:
    enabled: true
    # When using AKS, specify the appropriate storage class for ReadWriteMany support
    storageClass: ""  # Empty string will use cluster default
    size: "10Gi"
    accessMode: ReadWriteMany


# Dind daemon chart configuration
dind-daemon:
  enabled: true
  resources:
    limits:
      cpu: 4000m
      memory: 16Gi
    requests:
      cpu: 500m
      memory: 1Gi

# Service-specific configurations
redis:
  auth:
    enabled: false  # Disable authentication for simplicity
  architecture: standalone  # Use single instance instead of cluster
  master:
    persistence:
      enabled: true
      size: 8Gi # 8GB of storage for redis, how much is needed?
      storageClass: managed-premium

    configuration: |-
      appendonly yes
      appendfsync everysec
      no-appendfsync-on-rewrite no
      auto-aof-rewrite-percentage 100
      auto-aof-rewrite-min-size 64mb
    resources:
      limits:
        cpu: 250m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi
  # Add Docker registry authentication
  global:
    imagePullSecrets:
      - ghcr-auth
      - docker-auth

task-server:
  enabled: true
  # API authentication is configured with the following credentials:
  # API Key ID: 515cc8a0-3019-4c9f-8c1c-72d0b54ae561
  # API Token: VGuAC8axfOnFXKBB7irpNDOKcDjOlnyB (for client usage)
  # These values are set in the secret/config-map in config.yaml

task-downloader:
  enabled: true
  
scheduler:
  enabled: true

program-model:
  enabled: true

build-bot:
  replicaCount: 4
  enabled: true
  timer: 5000
  logLevel: "DEBUG"

fuzzer-bot:
  enabled: true

coverage-bot:
  enabled: true

tracer-bot:
  enabled: true

seed-gen:
  enabled: true

patcher:
  enabled: true

competition-api:
  enabled: true

mock-competition-api:
  enabled: ${MOCK_COMPETITION_API_ENABLED}

# Registry cache configuration
registry-cache:
  enabled: true
  persistence:
    enabled: true
    size: 10Gi

# PostgreSQL configuration for LiteLLM
litellm-db:
  enabled: true
  image:
    tag: "17.2.0"  # Use major.minor.patch format without specific OS details
  auth:
    username: litellm_user
    password: litellm_password11
    database: litellm
    enablePostgresUser: true
    postgresPassword: litellm_password11  # Set a postgres admin password
  primary:
    resources:
      limits:
        cpu: 200m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi
  readReplicas:
    replicaCount: 0  # No read replicas needed for this simple setup
  global:
    imagePullSecrets:
      - ghcr-auth
      - docker-auth

# LiteLLM configuration
litellm-helm:
  # Override the name to ensure it matches our references
  nameOverride: "litellm"
  
  # Number of workers for the LiteLLM service
  replicaCount: 1
  
  # Set the service port
  service:
    port: 4000
  
  # Environment variables
  envVars:
    DATABASE_URL: "postgresql://litellm_user:litellm_password11@buttercup-litellm-db-postgresql:5432/litellm"
    # API keys are now provided through Kubernetes secrets
  
  # Use environment secrets for API keys
  # For subcharts, we need to use a static name that will be templated at the parent level
  environmentSecrets:
    - "buttercup-litellm-api-secrets"
  
  # Docker authentication
  global:
    imagePullSecrets:
      - ghcr-auth
      - docker-auth
  
  # Direct inclusion of the litellm_config.yaml content
  proxy_config:
    model_list:
      - model_name: azure-gpt-4o
        litellm_params:
          model: azure/gpt-4o
          api_base: os.environ/AZURE_API_BASE
          api_key: os.environ/AZURE_API_KEY
          tpm: 30000
          rpm: 1800

      - model_name: azure-gpt-4o-mini
        litellm_params:
          model: azure/gpt-4o-mini
          api_base: os.environ/AZURE_API_BASE
          api_key: os.environ/AZURE_API_KEY
          tpm: 50000
          rpm: 5000

      - model_name: azure-o3-mini
        litellm_params:
          model: azure/o3-mini
          api_base: os.environ/AZURE_API_BASE
          api_key: os.environ/AZURE_API_KEY
          api_version: 2024-12-01-preview
          tpm: 50000
          rpm: 50

      - model_name: azure-o1
        litellm_params:
          model: azure/o1
          api_base: os.environ/AZURE_API_BASE
          api_key: os.environ/AZURE_API_KEY
          api_version: 2024-12-01-preview
          tpm: 30000
          rpm: 50

      - model_name: openai-gpt-4o
        litellm_params:
          model: openai/gpt-4o
          api_key: os.environ/OPENAI_API_KEY

      - model_name: openai-gpt-4o-mini
        litellm_params:
          model: openai/gpt-4o-mini
          api_key: os.environ/OPENAI_API_KEY

      - model_name: openai-o3-mini
        litellm_params:
          model: openai/o3-mini
          api_key: os.environ/OPENAI_API_KEY

      - model_name: openai-o1
        litellm_params:
          model: openai/o1
          api_key: os.environ/OPENAI_API_KEY

      - model_name: claude-3.5-sonnet
        litellm_params:
          model: anthropic/claude-3-5-sonnet-20241022
          api_key: os.environ/ANTHROPIC_API_KEY

      - model_name: claude-3.5-haiku
        litellm_params:
          model: anthropic/claude-3-5-haiku-20241022
          api_key: os.environ/ANTHROPIC_API_KEY

      - model_name: claude-3.7-sonnet
        litellm_params:
          model: anthropic/claude-3-7-sonnet-20250219
          api_key: os.environ/ANTHROPIC_API_KEY

    general_settings:
      master_key: os.environ/BUTTERCUP_LITELLM_KEY

